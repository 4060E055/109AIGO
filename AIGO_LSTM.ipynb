{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM","provenance":[],"collapsed_sections":[],"mount_file_id":"1d_llCwln6TjiPNYO-w9sP9zEF4ITvEzH","authorship_tag":"ABX9TyNzuEj8Al5ZnSyBm2XywUiD"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"BEKAexhcW1bR"},"source":["import tensorflow as tf\n","import pandas as pd\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import csv\n","from numpy import genfromtxt\n","import numpy as np\n","from keras.utils import np_utils\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical\n","from sklearn import preprocessing\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","from sklearn.preprocessing import MinMaxScaler\n","import math\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","\n","print(\"GPU: \", tf.test.is_gpu_available())\n","\n","# data preprocessing and data path\n","data = genfromtxt(\"/content/drive/My Drive/訓練資料/America/LS.csv\",  delimiter=\",\", dtype=str)\n","#print(data)\n","#print(data.shape)\n","\n","data = data.astype(np.float32)\n","data2 = data[:,1]\n","\n","data2 = np.reshape(data2, (data2.shape[0], 1))\n","print(data2)\n","scaler = MinMaxScaler(feature_range=(0,1))\n","data2 = scaler.fit_transform(data2)\n","\n","def create_dataset(dataset, look_back=1):\n","    dataX, dataY = [], []\n","    for i in range(len(dataset)-look_back-1):\n","        a = dataset[i:i+look_back,0]\n","        dataX.append(a)\n","        dataY.append(dataset[i+look_back,0])\n","    return np.array(dataX), np.array(dataY)\n","\n","\n","train_size = int(len(data2) * 0.67)\n","look_back = 1\n","train_dataX, train_dataY = create_dataset(data2[0:train_size,:], look_back)\n","test_dataX, test_dataY = create_dataset(data2[train_size:len(data2)], look_back)\n","\n","\n","train_dataX = np.reshape(train_dataX, (train_dataX.shape[0], 1, train_dataX.shape[1]))\n","test_dataX = np.reshape(test_dataX, (test_dataX.shape[0], 1, test_dataX.shape[1]))\n","print(\"data2.shape: \", data2.shape)\n","print(\"train_dataY: \", train_dataY.shape)\n","\n","\n","model = Sequential()\n","model.add(LSTM(4, input_shape=(1, 1)))\n","model.add(Dense(1))\n","model.compile(loss='mse', optimizer=\"adam\")\n","\n","#訓練模型參數設定\n","\n","history = model.fit(train_dataX, train_dataY, epochs=5, batch_size=1, verbose=1)\n","\n","model.save('lstm.h5')\n","trainPredict = model.predict(train_dataX)\n","testPredict = model.predict(test_dataX)\n","\n","\n","trainScore = math.sqrt(mean_squared_error(train_dataY, trainPredict[:,0]))\n","testScore = math.sqrt(mean_squared_error(test_dataY, testPredict[:,0]))\n","print('TrainScore: %.2f RMSE(norm)' % (trainScore))\n","print('TestScore: %.2f RMSE(norm)' % (testScore))\n","\n","# 恢復原始數據 scale\n","trainPredict = scaler.inverse_transform(trainPredict)\n","train_dataY = scaler.inverse_transform([train_dataY])\n","testPredict = scaler.inverse_transform(testPredict)\n","test_dataY = scaler.inverse_transform([test_dataY])\n","#print('testPredict = ', (testPredict))\n","#print('testPredict = ', (test_dataY))\n","print('dataTpye：',type(testPredict))\n","print('dataTpye：',type(test_dataY))\n","\n","df0 = pd.DataFrame(testPredict,columns=['predict']) #ndarray 轉dataframe\n","df1 = pd.DataFrame(test_dataY.T)\n","\n","df0['test_Y'] = df1\n","\n","dataname=\"X.csv\"  #savefilename\n","df0.to_csv(dataname,index=0)\n","\n","\n","trainPredictPlot = np.empty_like(data2)\n","trainPredictPlot[:, :] = np.nan\n","trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n","\n","# 畫測試資料趨勢圖\n","# shift test predictions for plotting\n","testPredictPlot = np.empty_like(data2)\n","testPredictPlot[:, :] = np.nan \n","testPredictPlot[len(trainPredict)+(look_back*2)+1:len(data2)-1, :] = testPredict\n","\n","# 畫原始資料趨勢圖\n","#plot baseline and predictions\n","plt.plot(scaler.inverse_transform(data2))\n","plt.plot(trainPredictPlot)\n","plt.plot(testPredictPlot)\n","plt.show()"],"execution_count":null,"outputs":[]}]}